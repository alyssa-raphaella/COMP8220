{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assessed_Task3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDu+yKSklGK1w/aAt99t/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyssa-raphaella/COMP8220/blob/master/Assessment/Assessed_Task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX9DGVheAh65",
        "colab_type": "text"
      },
      "source": [
        "### Google Drive Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfOnRfRc9XEa",
        "colab_type": "code",
        "outputId": "93ff91d0-413b-4ef9-cd6d-20a629d04059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# mount drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_path = 'gdrive/My Drive/COMP8220-GColab/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpB7YvJeAoys",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMzsrx2d9bzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wxeFeQR8Ent",
        "colab_type": "code",
        "outputId": "f2336b81-5407-4633-addc-167127c48a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "import pandas as pd\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4cXWklyD0_U",
        "colab_type": "text"
      },
      "source": [
        "### Caltech-101 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdY2WmEP9sKZ",
        "colab_type": "code",
        "outputId": "66c168fe-782a-41e2-e795-7468be187bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!echo \"Downloading 101_Object_Categories for image notebooks\"\n",
        "!curl -L -o 101_ObjectCategories.tar.gz --progress-bar http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\n",
        "!tar -xzf 101_ObjectCategories.tar.gz\n",
        "!rm 101_ObjectCategories.tar.gz\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 101_Object_Categories for image notebooks\n",
            "######################################################################## 100.0%\n",
            "101_ObjectCategories  gdrive  images  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFxbf0HYD7tY",
        "colab_type": "text"
      },
      "source": [
        "##### Remove 5 largest categories in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMp5YlfaACh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = '101_ObjectCategories'\n",
        "exclude = ['BACKGROUND_Google', 'Motorbikes', 'airplanes', 'Faces_easy', 'Faces']\n",
        "\n",
        "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
        "categories = [c for c in categories if c not in [os.path.join(root, e) for e in exclude]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdP7QnkpH4Fg",
        "colab_type": "text"
      },
      "source": [
        "##### Load all images from root folder, then pre-process data into an image and input vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjmbdOMnAWiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function to load image and return it and input vector\n",
        "def get_image(path):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return img, x\n",
        "\n",
        "data = []\n",
        "for c, category in enumerate(categories):\n",
        "    images = [os.path.join(dp, f) for dp, dn, filenames \n",
        "              in os.walk(category) for f in filenames \n",
        "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
        "    for img_path in images:\n",
        "        img, x = get_image(img_path)\n",
        "        data.append({'x':np.array(x[0]), 'y':c})\n",
        "\n",
        "# count the number of classes\n",
        "num_classes = len(categories)\n",
        "\n",
        "# randomize data order\n",
        "random.shuffle(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8QYijE5POkS",
        "colab_type": "text"
      },
      "source": [
        "##### Split data to Training, Validation, and Test sets ( 70%, 15%, 15% )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLGi4ssRG_fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_data = len(data)\n",
        "\n",
        "# data split (train, val, test)\n",
        "train_split, test_split = 0.70, 0.85\n",
        "\n",
        "idx_val = int(train_split * num_data)\n",
        "idx_test = int(test_split * num_data)\n",
        "\n",
        "train = data[:idx_val]\n",
        "val = data[idx_val:idx_test]\n",
        "test = data[idx_test:]\n",
        "\n",
        "x_train, y_train = np.array([t['x'] for t in train]), [t['y'] for t in train]\n",
        "x_val, y_val = np.array([t['x'] for t in val]), [t['y'] for t in val]\n",
        "x_test, y_test = np.array([t['x'] for t in test]), [t['y'] for t in test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wH23B8HBQ5g",
        "colab_type": "text"
      },
      "source": [
        "##### Normalization of data and label conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It8h07dcItCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize data\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_val = x_val.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# convert labels to one-hot vectors\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To1mlcFwSUjC",
        "colab_type": "text"
      },
      "source": [
        "### CNN Architecture\n",
        "##### Filters\n",
        "* The model has 64 filters in the first convolutional layer, then doubled the number of filters after reducing the spatial dimension of the initial input with MaxPooling\n",
        "\n",
        "##### Kernel Size\n",
        "* The first convolutional layer has kernel size of (5,5) due to the input image size is 224 x 224 which is large\n",
        "* Kernel Size of (3,3) for the second layer due to the MaxPooling outputs data that has size of 110 x 110, which is not that big, that's why the kernel size is reduced \n",
        "\n",
        "##### Padding\n",
        "* _Same_ padding is used for the two layers to maintain the dimension of the input, which improves the performance of the architecture by keeping the information at the borders of the data \n",
        "\n",
        "#### Activation\n",
        "* Activation used for all layers is _relu_ for computational efficiency, since images are being processed by the architecture\n",
        "\n",
        "#### Regularizer\n",
        "* L2 regularization was used with 0.01 value, to reduce the effects of overfitting\n",
        "\n",
        "#### Dropout Layers\n",
        "* 2 dropout layers were applied in the architecture to regularize the data\n",
        "* The first dropout layer was placed before flattening the array, to regularize the data before flattening it\n",
        "* The second layer was placed before the last dense layer, to regularize the data before the final processing of the data output\n",
        "\n",
        "#### Dense Layers\n",
        "* 3 dense layers were used, to reduce the input size and the computational complexity\n",
        "* These dense layers were used in the architecture to reduce the computational complexity of the model, which leads to faster processing time\n",
        "* The first two dense layers have 256 neurons, which is large enough considering the size of the input data\n",
        "* 97 neurons were used in the last dense layer, because there are 97 expected ouputs for the Caltech-101 dataset\n",
        "\n",
        "#### Softmax (activation)\n",
        "* Softmax was used in the last layer of each architectural model in this notebook\n",
        "* Softmax was used because it outputs the probability distribution of the image in each class, which gives better image classification compared to binary activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-30Dc8P_4Pd",
        "colab_type": "text"
      },
      "source": [
        "### With Dropout Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFMldiLux3Os",
        "colab_type": "code",
        "outputId": "be12e978-ae0a-4d2b-b659-18c4b6ab4050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Conv2D(filters = 64, kernel_size= (5,5), padding = 'same', activation = \"relu\", input_shape = (224, 224, 3)))\n",
        "model_1.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model_1.add(Conv2D(filters = 128, kernel_size =(3,3), padding = 'same', activation = \"relu\"))\n",
        "model_1.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(256, activation = \"relu\"))\n",
        "model_1.add(Dense(256, activation = \"relu\", kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 64)      4864      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 401408)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               102760704 \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 97)                24929     \n",
            "=================================================================\n",
            "Total params: 102,930,145\n",
            "Trainable params: 102,930,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiDbE8Zj1ctA",
        "colab_type": "code",
        "outputId": "31349bbb-c8dd-4f7a-9ce1-a74bce2d4a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "model_1.compile(optimizer = Adam(learning_rate = 3e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_1 = model_1.fit(x_train, y_train, validation_data=(x_val, y_val), epochs = 20)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4346 samples, validate on 931 samples\n",
            "Epoch 1/20\n",
            "4346/4346 [==============================] - 19s 4ms/step - loss: 6.2318 - accuracy: 0.0541 - val_loss: 5.3902 - val_accuracy: 0.0945\n",
            "Epoch 2/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 4.8254 - accuracy: 0.1420 - val_loss: 4.3318 - val_accuracy: 0.2041\n",
            "Epoch 3/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 3.7913 - accuracy: 0.2614 - val_loss: 3.6519 - val_accuracy: 0.2825\n",
            "Epoch 4/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 2.8445 - accuracy: 0.4091 - val_loss: 3.2570 - val_accuracy: 0.3566\n",
            "Epoch 5/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 1.9612 - accuracy: 0.5769 - val_loss: 3.2201 - val_accuracy: 0.3663\n",
            "Epoch 6/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 1.2676 - accuracy: 0.7386 - val_loss: 3.4008 - val_accuracy: 0.3566\n",
            "Epoch 7/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.8597 - accuracy: 0.8364 - val_loss: 3.6479 - val_accuracy: 0.3631\n",
            "Epoch 8/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.6495 - accuracy: 0.8958 - val_loss: 3.7483 - val_accuracy: 0.3759\n",
            "Epoch 9/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.4999 - accuracy: 0.9372 - val_loss: 3.9964 - val_accuracy: 0.3781\n",
            "Epoch 10/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.4504 - accuracy: 0.9452 - val_loss: 4.1094 - val_accuracy: 0.3878\n",
            "Epoch 11/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.3704 - accuracy: 0.9648 - val_loss: 4.3862 - val_accuracy: 0.3802\n",
            "Epoch 12/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.3621 - accuracy: 0.9669 - val_loss: 4.3603 - val_accuracy: 0.3792\n",
            "Epoch 13/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.3229 - accuracy: 0.9751 - val_loss: 4.5283 - val_accuracy: 0.3620\n",
            "Epoch 14/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.3065 - accuracy: 0.9768 - val_loss: 4.5887 - val_accuracy: 0.3749\n",
            "Epoch 15/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.3019 - accuracy: 0.9768 - val_loss: 4.5537 - val_accuracy: 0.3792\n",
            "Epoch 16/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2920 - accuracy: 0.9795 - val_loss: 4.6557 - val_accuracy: 0.3749\n",
            "Epoch 17/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2749 - accuracy: 0.9781 - val_loss: 4.6749 - val_accuracy: 0.3899\n",
            "Epoch 18/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2682 - accuracy: 0.9816 - val_loss: 4.5233 - val_accuracy: 0.3792\n",
            "Epoch 19/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2435 - accuracy: 0.9871 - val_loss: 4.6469 - val_accuracy: 0.3588\n",
            "Epoch 20/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2433 - accuracy: 0.9864 - val_loss: 4.5551 - val_accuracy: 0.3824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNdeYNLnAFAG",
        "colab_type": "text"
      },
      "source": [
        "### Without Dropout Layers\n",
        "* Same architecture was used, but dropout layers were removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yohf1pZmOhkT",
        "colab_type": "code",
        "outputId": "f39afe8b-d2a1-42d9-a171-99b9d8ed4b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Conv2D(filters = 64, kernel_size= (5,5), padding = 'same', activation = \"relu\", input_shape = (224, 224, 3)))\n",
        "model_2.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model_2.add(Conv2D(filters = 128, kernel_size =(3,3), padding = 'same', activation = \"relu\"))\n",
        "model_2.add(MaxPooling2D(pool_size = (2,2)))\n",
        "#model_1.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(256, activation = \"relu\"))\n",
        "model_2.add(Dense(256, activation = \"relu\", kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "#model_1.add(Dropout(0.5))\n",
        "model_2.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 224, 224, 64)      4864      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 401408)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               102760704 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 97)                24929     \n",
            "=================================================================\n",
            "Total params: 102,930,145\n",
            "Trainable params: 102,930,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91AjsljpOxIC",
        "colab_type": "code",
        "outputId": "b261885d-4e27-4234-9355-42bd5d00ccda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "model_2.compile(optimizer = Adam(learning_rate = 3e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_2 = model_2.fit(x_train, y_train, validation_data=(x_val, y_val), epochs = 20)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4346 samples, validate on 931 samples\n",
            "Epoch 1/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 6.0130 - accuracy: 0.1243 - val_loss: 4.9461 - val_accuracy: 0.2256\n",
            "Epoch 2/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 3.8650 - accuracy: 0.3539 - val_loss: 3.8314 - val_accuracy: 0.3265\n",
            "Epoch 3/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 2.0174 - accuracy: 0.6710 - val_loss: 3.7833 - val_accuracy: 0.3469\n",
            "Epoch 4/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.8419 - accuracy: 0.9422 - val_loss: 4.3264 - val_accuracy: 0.3641\n",
            "Epoch 5/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.5581 - accuracy: 0.9880 - val_loss: 4.7006 - val_accuracy: 0.3631\n",
            "Epoch 6/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.4671 - accuracy: 0.9972 - val_loss: 4.5748 - val_accuracy: 0.3985\n",
            "Epoch 7/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.4164 - accuracy: 0.9998 - val_loss: 4.9150 - val_accuracy: 0.3770\n",
            "Epoch 8/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.4275 - accuracy: 0.9929 - val_loss: 4.6372 - val_accuracy: 0.3534\n",
            "Epoch 9/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.3593 - accuracy: 0.9998 - val_loss: 4.6715 - val_accuracy: 0.3845\n",
            "Epoch 10/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.3307 - accuracy: 1.0000 - val_loss: 4.7096 - val_accuracy: 0.3931\n",
            "Epoch 11/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.3065 - accuracy: 1.0000 - val_loss: 4.7304 - val_accuracy: 0.3910\n",
            "Epoch 12/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2837 - accuracy: 1.0000 - val_loss: 4.7438 - val_accuracy: 0.3963\n",
            "Epoch 13/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2619 - accuracy: 1.0000 - val_loss: 4.7196 - val_accuracy: 0.4006\n",
            "Epoch 14/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2411 - accuracy: 1.0000 - val_loss: 4.7225 - val_accuracy: 0.3996\n",
            "Epoch 15/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2212 - accuracy: 1.0000 - val_loss: 4.6928 - val_accuracy: 0.3974\n",
            "Epoch 16/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.2021 - accuracy: 1.0000 - val_loss: 4.6692 - val_accuracy: 0.3953\n",
            "Epoch 17/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.1839 - accuracy: 1.0000 - val_loss: 4.6201 - val_accuracy: 0.3996\n",
            "Epoch 18/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.1666 - accuracy: 1.0000 - val_loss: 4.5982 - val_accuracy: 0.3974\n",
            "Epoch 19/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.1503 - accuracy: 1.0000 - val_loss: 4.5616 - val_accuracy: 0.3996\n",
            "Epoch 20/20\n",
            "4346/4346 [==============================] - 12s 3ms/step - loss: 0.1349 - accuracy: 1.0000 - val_loss: 4.5096 - val_accuracy: 0.4006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai6SWdLrBpOm",
        "colab_type": "text"
      },
      "source": [
        "#### Test Loss and Accuracy\n",
        "* There is no big difference between the loss and accuracy of the the two models\n",
        "* Test Accuracy vary from 32% to 42%\n",
        "* The model with dropout might have higher accuracy in one run, and higher accuracy with the model without dropout in another run, which is caused by the randomness in the input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKgDYMkx0xLr",
        "colab_type": "code",
        "outputId": "4fff1d88-ce40-4f3c-937c-f6bdb0143e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "loss_1, accuracy_1 = model_1.evaluate(x_test, y_test, verbose=0)\n",
        "loss_2, accuracy_2 = model_2.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "result_list = []\n",
        "result_list.append([\"with Dropout\", loss_1, accuracy_1])\n",
        "result_list.append([\"without Dropout\", loss_2, accuracy_2])\n",
        "\n",
        "result_pd = pd.DataFrame(result_list, columns = [\"Model\", \"Loss\", \"Accuracy\"])\n",
        "#result_pd = result_pd.set_index('Model')\n",
        "result_pd"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>with Dropout</td>\n",
              "      <td>4.405936</td>\n",
              "      <td>0.386266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>without Dropout</td>\n",
              "      <td>4.074606</td>\n",
              "      <td>0.420601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Model      Loss  Accuracy\n",
              "0     with Dropout  4.405936  0.386266\n",
              "1  without Dropout  4.074606  0.420601"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUWkwFVBECrP",
        "colab_type": "text"
      },
      "source": [
        "#### Validation Loss and Accuracy Plot\n",
        "##### Loss\n",
        "* Architecture with dropout layer achieved the lowest loss compared to the model without dropout layer for the validation set\n",
        "* Dropout Layer gradually decreases the data loss per epoch\n",
        "* Dropout also gradually increases the data loss per epoch, which is a sign of overfitting\n",
        "* Early stopping resolves overfitting which may improve the performance of the models, but it was not used in this notebook to observe the behavior of the validation loss and validation accuracy of each model\n",
        "\n",
        "##### Accuracy\n",
        "* The model with dropout layer has gradually increased, then stabilized in a certain accuracy rate with less noise compared to the model without dropout layer as seen in the plot below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnAvea7-dk_z",
        "colab_type": "code",
        "outputId": "fb4f8179-ed23-4611-cc04-3fbfd5f19468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax_1 = fig.add_subplot(121)\n",
        "ax_1.plot(history_1.history[\"val_loss\"], label = 'with dropout')\n",
        "ax_1.plot(history_2.history[\"val_loss\"], label = 'without dropout')\n",
        "ax_1.set_title(\"validation loss\")\n",
        "ax_1.set_xlabel(\"epochs\")\n",
        "ax_1.legend()\n",
        "\n",
        "ax_2 = fig.add_subplot(122)\n",
        "ax_2.plot(history_1.history[\"val_accuracy\"], label = 'with dropout')\n",
        "ax_2.plot(history_2.history[\"val_accuracy\"], label = 'without dropout')\n",
        "ax_2.set_title(\"validation accuracy\")\n",
        "ax_2.set_xlabel(\"epochs\")\n",
        "ax_2.set_ylim(0, 1)\n",
        "ax_2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMQqq4iHeP92",
        "colab_type": "text"
      },
      "source": [
        "#### Loss Plots\n",
        "##### Training Set\n",
        "* The loss in the training set decreased more gradual until it stablelize in a certain rate, for the model with dropout layer\n",
        "\n",
        "##### Validation Set\n",
        "* The validation loss of model with dropout layer has less noise and more regularized as seen in the plot below\n",
        "* It also gradually decreased the validation loss like in the training set, for the model with dropout layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EDUTY9u6Qjq",
        "colab_type": "code",
        "outputId": "5cfaed73-7ad6-47ce-9492-60aabe53020d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax_3 = fig.add_subplot(121)\n",
        "ax_3.plot(history_1.history[\"loss\"], label = 'Training Loss')\n",
        "ax_3.plot(history_1.history[\"val_loss\"], label = 'Validation Loss')\n",
        "ax_3.set_title(\"Loss Plot (with dropout)\")\n",
        "ax_3.set_xlabel(\"epochs\")\n",
        "ax_3.legend()\n",
        "\n",
        "ax_4 = fig.add_subplot(122)\n",
        "ax_4.plot(history_2.history[\"loss\"], label = 'Training Loss')\n",
        "ax_4.plot(history_2.history[\"val_loss\"], label = 'Validation Loss')\n",
        "ax_4.set_title(\"Loss Plot (without dropout)\")\n",
        "ax_4.set_xlabel(\"epochs\")\n",
        "ax_4.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f_nV9XhE2Fr",
        "colab_type": "text"
      },
      "source": [
        "### ResNet50V2 Architechture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuCIpNmI2NVy",
        "colab_type": "code",
        "outputId": "c96f44b9-8eb0-4e6a-d4b1-d49bb2a89682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet = keras.applications.ResNet50V2(weights = 'imagenet', include_top = True)\n",
        "resnet.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102875136/102869336 [==============================] - 3s 0us/step\n",
            "Model: \"resnet50v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d_5[0][0]            \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_6[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_7[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "probs (Dense)                   (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 25,613,800\n",
            "Trainable params: 25,568,360\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giBJdhWhFXAa",
        "colab_type": "text"
      },
      "source": [
        "### One Frozen Layer\n",
        "* Changed the last layer of ResNet50V2 with _Dense(num_classes, activation = 'softmax')_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gjVC6R8_LrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_layer = Dense(num_classes, activation = 'softmax')\n",
        "\n",
        "resnet_in = resnet.input\n",
        "resnet_out = new_layer(resnet.layers[-2].output)\n",
        "\n",
        "model_3 = Model(resnet_in, resnet_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4egK6ljPKJZK",
        "colab_type": "text"
      },
      "source": [
        "* All layers were frozen except for the last layer, which is the _new_layer_ that has 97 outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM0JHOpD_OpK",
        "colab_type": "code",
        "outputId": "c42f2fe9-edf5-4d2a-f5a2-79dfdcc97c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for l, layer in enumerate(model_3.layers[:-1]):\n",
        "  layer.trainable = False\n",
        "\n",
        "for l, layer in enumerate(model_3.layers[-1:]):\n",
        "  layer.trainable = True\n",
        "\n",
        "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_3.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d_5[0][0]            \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_6[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_7[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 97)           198753      avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,763,553\n",
            "Trainable params: 198,753\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1MQEVzrdmuR",
        "colab_type": "code",
        "outputId": "20ab5871-7a3f-4cf2-aed7-26a974562023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "history_3 = model_3.fit(x_train, y_train, validation_data=(x_val, y_val), epochs = 20)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4346 samples, validate on 931 samples\n",
            "Epoch 1/20\n",
            "4346/4346 [==============================] - 17s 4ms/step - loss: 1.7538 - accuracy: 0.6275 - val_loss: 0.5378 - val_accuracy: 0.8593\n",
            "Epoch 2/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.3438 - accuracy: 0.9342 - val_loss: 0.4449 - val_accuracy: 0.8818\n",
            "Epoch 3/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.1802 - accuracy: 0.9703 - val_loss: 0.4086 - val_accuracy: 0.8926\n",
            "Epoch 4/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.1169 - accuracy: 0.9809 - val_loss: 0.3935 - val_accuracy: 0.8990\n",
            "Epoch 5/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0802 - accuracy: 0.9915 - val_loss: 0.3831 - val_accuracy: 0.8980\n",
            "Epoch 6/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0606 - accuracy: 0.9942 - val_loss: 0.4071 - val_accuracy: 0.8990\n",
            "Epoch 7/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0458 - accuracy: 0.9975 - val_loss: 0.3960 - val_accuracy: 0.8969\n",
            "Epoch 8/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0362 - accuracy: 0.9988 - val_loss: 0.3999 - val_accuracy: 0.8904\n",
            "Epoch 9/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0304 - accuracy: 0.9979 - val_loss: 0.3841 - val_accuracy: 0.8926\n",
            "Epoch 10/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0246 - accuracy: 0.9995 - val_loss: 0.3797 - val_accuracy: 0.8969\n",
            "Epoch 11/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0225 - accuracy: 0.9984 - val_loss: 0.3877 - val_accuracy: 0.8990\n",
            "Epoch 12/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0209 - accuracy: 0.9991 - val_loss: 0.4019 - val_accuracy: 0.9055\n",
            "Epoch 13/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0177 - accuracy: 0.9991 - val_loss: 0.4055 - val_accuracy: 0.9055\n",
            "Epoch 14/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0150 - accuracy: 0.9993 - val_loss: 0.4094 - val_accuracy: 0.9023\n",
            "Epoch 15/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 0.3954 - val_accuracy: 0.9055\n",
            "Epoch 16/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0125 - accuracy: 0.9988 - val_loss: 0.4096 - val_accuracy: 0.9044\n",
            "Epoch 17/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0108 - accuracy: 0.9995 - val_loss: 0.4146 - val_accuracy: 0.9044\n",
            "Epoch 18/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9055\n",
            "Epoch 19/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0106 - accuracy: 0.9993 - val_loss: 0.4184 - val_accuracy: 0.9044\n",
            "Epoch 20/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.8980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkyhYEx57Zs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_3, accuracy_3 = model_3.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "result_list = []\n",
        "result_list.append([\"1 layer frozen\", loss_3, accuracy_3])\n",
        "\n",
        "result_pd.loc[len(result_pd)] = result_list[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqRA0XV3FdZ2",
        "colab_type": "text"
      },
      "source": [
        "#### Data Augmentation Application\n",
        "##### These data augmentations are chosen because they are the typical variations in images\n",
        "* _rotation_range_ of 90, due to images can be landscape or portrait which has 90 degree difference from each other\n",
        "* _width_shift_range_ and _height_shift_range_ of 0.1, due to images are shifted only by 10% which means the subject is still whole in the image\n",
        "* _zoom_range_ 0.8 to 1.3, due to the subject is still recognizable in 0.8 zoom out, whole and recognizable in 1.2 zoom in\n",
        "* _horizontal_flip_ is True\n",
        "* _fill_mode_ is nerest, due to the probability of the missing piece in an image has same color or color gradient to it's neighbor is high\n",
        "* _brightness_range_ is 0.3 to 1.2, due to the subject is still recognizable in with this brightness range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrsmrsIBKb0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rotation_range=90,\n",
        "                             width_shift_range = 0.1,\n",
        "                             height_shift_range = 0.1,\n",
        "                             zoom_range = (0.8, 1.3),\n",
        "                             horizontal_flip = True,\n",
        "                             fill_mode = 'nearest',\n",
        "                             brightness_range = (0.3, 1.2))\n",
        "\n",
        "x_train_aug = x_train\n",
        "datagen.fit(x_train_aug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc0uA8V3KjOH",
        "colab_type": "code",
        "outputId": "f178c342-ee9d-46c4-bb91-f4783252bfd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "batch_size = 32\n",
        "history_5 = model_3.fit(datagen.flow(x_train_aug, y_train, batch_size), steps_per_epoch = len(x_train_aug)/batch_size, epochs = 20, \n",
        "                        validation_data = (x_val, y_val))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "136/135 [==============================] - 55s 407ms/step - loss: 0.9496 - accuracy: 0.7570 - val_loss: 0.6997 - val_accuracy: 0.8765\n",
            "Epoch 2/20\n",
            "136/135 [==============================] - 54s 394ms/step - loss: 0.6099 - accuracy: 0.8272 - val_loss: 0.6614 - val_accuracy: 0.8786\n",
            "Epoch 3/20\n",
            "136/135 [==============================] - 54s 394ms/step - loss: 0.4908 - accuracy: 0.8587 - val_loss: 0.6640 - val_accuracy: 0.8786\n",
            "Epoch 4/20\n",
            "136/135 [==============================] - 54s 397ms/step - loss: 0.4471 - accuracy: 0.8695 - val_loss: 0.6309 - val_accuracy: 0.8765\n",
            "Epoch 5/20\n",
            "136/135 [==============================] - 54s 394ms/step - loss: 0.3781 - accuracy: 0.8845 - val_loss: 0.6776 - val_accuracy: 0.8754\n",
            "Epoch 6/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.3417 - accuracy: 0.8962 - val_loss: 0.6581 - val_accuracy: 0.8722\n",
            "Epoch 7/20\n",
            "136/135 [==============================] - 54s 394ms/step - loss: 0.3219 - accuracy: 0.9011 - val_loss: 0.7025 - val_accuracy: 0.8657\n",
            "Epoch 8/20\n",
            "136/135 [==============================] - 53s 393ms/step - loss: 0.3146 - accuracy: 0.9098 - val_loss: 0.6734 - val_accuracy: 0.8786\n",
            "Epoch 9/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.2947 - accuracy: 0.9043 - val_loss: 0.6625 - val_accuracy: 0.8808\n",
            "Epoch 10/20\n",
            "136/135 [==============================] - 53s 392ms/step - loss: 0.2864 - accuracy: 0.9142 - val_loss: 0.7550 - val_accuracy: 0.8733\n",
            "Epoch 11/20\n",
            "136/135 [==============================] - 53s 392ms/step - loss: 0.2598 - accuracy: 0.9185 - val_loss: 0.6445 - val_accuracy: 0.8797\n",
            "Epoch 12/20\n",
            "136/135 [==============================] - 53s 393ms/step - loss: 0.2418 - accuracy: 0.9257 - val_loss: 0.6888 - val_accuracy: 0.8647\n",
            "Epoch 13/20\n",
            "136/135 [==============================] - 53s 393ms/step - loss: 0.2459 - accuracy: 0.9185 - val_loss: 0.7400 - val_accuracy: 0.8668\n",
            "Epoch 14/20\n",
            "136/135 [==============================] - 53s 392ms/step - loss: 0.2394 - accuracy: 0.9261 - val_loss: 0.7357 - val_accuracy: 0.8700\n",
            "Epoch 15/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.2325 - accuracy: 0.9289 - val_loss: 0.7534 - val_accuracy: 0.8636\n",
            "Epoch 16/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.2126 - accuracy: 0.9307 - val_loss: 0.7081 - val_accuracy: 0.8647\n",
            "Epoch 17/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.2209 - accuracy: 0.9294 - val_loss: 0.7110 - val_accuracy: 0.8679\n",
            "Epoch 18/20\n",
            "136/135 [==============================] - 54s 397ms/step - loss: 0.1961 - accuracy: 0.9397 - val_loss: 0.7228 - val_accuracy: 0.8700\n",
            "Epoch 19/20\n",
            "136/135 [==============================] - 54s 396ms/step - loss: 0.1936 - accuracy: 0.9390 - val_loss: 0.7683 - val_accuracy: 0.8604\n",
            "Epoch 20/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.1872 - accuracy: 0.9416 - val_loss: 0.8128 - val_accuracy: 0.8636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lohPM3CiKubw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_5, accuracy_5 = model_3.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "result_list.append([\"augmented data (1 layer ResNet50)\", loss_5, accuracy_5])\n",
        "\n",
        "result_pd.loc[len(result_pd)] = result_list[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vs4k5ClFkfV",
        "colab_type": "text"
      },
      "source": [
        "### Two Frozen Layers\n",
        "* _Trainable Layers_ are the last convolution layer (input and output) and the last layer of the network\n",
        "* The _last convolution layer_ was unfrozen due to the last layers of the network were focused on specific tasks, unlike the upper parts of the network which identifies general features. Which means the weight updates affect the accuracy and loss more\n",
        "* Freezing the upper layers of the model speedup performance but decreases accuracy and increases loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki_RJj-resl5",
        "colab_type": "code",
        "outputId": "13d734e5-ae6c-496e-a3dc-dc40cb517a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_4 = Model(resnet_in, resnet_out)\n",
        "\n",
        "for l, layer in enumerate(model_4.layers[:-6]):\n",
        "  layer.trainable = False\n",
        "\n",
        "for l, layer in enumerate(model_4.layers[-4:-1]):\n",
        "  layer.trainable = False\n",
        "\n",
        "# last layer\n",
        "for l, layer in enumerate(model_4.layers[-1:]):\n",
        "  layer.trainable = True\n",
        "\n",
        "# in and out of last convolution layer\n",
        "for l, layer in enumerate(model_4.layers[-6:-4]):\n",
        "  layer.trainable = True\n",
        "\n",
        "model_4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_4.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d_5[0][0]            \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_6[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_7[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 97)           198753      avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,763,553\n",
            "Trainable params: 1,249,377\n",
            "Non-trainable params: 22,514,176\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ft0n45Bg5sz",
        "colab_type": "code",
        "outputId": "d88fd2cf-0175-4c4a-db7e-e95dca900561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "history_4 = model_4.fit(x_train, y_train, validation_data=(x_val, y_val), epochs = 20)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4346 samples, validate on 931 samples\n",
            "Epoch 1/20\n",
            "4346/4346 [==============================] - 17s 4ms/step - loss: 0.1919 - accuracy: 0.9556 - val_loss: 3.8680 - val_accuracy: 0.7444\n",
            "Epoch 2/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.1216 - accuracy: 0.9659 - val_loss: 4.4519 - val_accuracy: 0.7487\n",
            "Epoch 3/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0556 - accuracy: 0.9827 - val_loss: 5.3260 - val_accuracy: 0.7368\n",
            "Epoch 4/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0603 - accuracy: 0.9848 - val_loss: 5.6853 - val_accuracy: 0.7304\n",
            "Epoch 5/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 5.8162 - val_accuracy: 0.7282\n",
            "Epoch 6/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0299 - accuracy: 0.9919 - val_loss: 4.1534 - val_accuracy: 0.7852\n",
            "Epoch 7/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 7.5120 - val_accuracy: 0.7014\n",
            "Epoch 8/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0574 - accuracy: 0.9867 - val_loss: 6.6334 - val_accuracy: 0.7637\n",
            "Epoch 9/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0497 - accuracy: 0.9880 - val_loss: 9.6168 - val_accuracy: 0.6810\n",
            "Epoch 10/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0354 - accuracy: 0.9899 - val_loss: 9.3530 - val_accuracy: 0.7261\n",
            "Epoch 11/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 7.3806 - val_accuracy: 0.7691\n",
            "Epoch 12/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 8.5246 - val_accuracy: 0.7583\n",
            "Epoch 13/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0204 - accuracy: 0.9963 - val_loss: 16.4439 - val_accuracy: 0.6337\n",
            "Epoch 14/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0184 - accuracy: 0.9959 - val_loss: 10.1295 - val_accuracy: 0.7648\n",
            "Epoch 15/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 14.2772 - val_accuracy: 0.6735\n",
            "Epoch 16/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0270 - accuracy: 0.9924 - val_loss: 13.0067 - val_accuracy: 0.7218\n",
            "Epoch 17/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 15.6395 - val_accuracy: 0.6702\n",
            "Epoch 18/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0211 - accuracy: 0.9947 - val_loss: 13.2270 - val_accuracy: 0.6992\n",
            "Epoch 19/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 14.1230 - val_accuracy: 0.7164\n",
            "Epoch 20/20\n",
            "4346/4346 [==============================] - 14s 3ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 14.1892 - val_accuracy: 0.7089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1D6zhzRhGpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_4, accuracy_4 = model_4.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "result_list = []\n",
        "result_list.append([\"2 layers frozen\", loss_4, accuracy_4])\n",
        "\n",
        "result_pd.loc[len(result_pd)] = result_list[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck165-ZLF0bm",
        "colab_type": "text"
      },
      "source": [
        "#### Data Augmentation Application\n",
        "* Retrained the ResNet50V2 with 2 trainable layers and augmented data as input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYZL2yqLLh4r",
        "colab_type": "code",
        "outputId": "cf038320-3033-4dfc-f47b-2f7a7d23d709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "history_6 = model_4.fit(datagen.flow(x_train_aug, y_train, batch_size), steps_per_epoch = len(x_train_aug)/batch_size, epochs = 20, \n",
        "                        validation_data = (x_val, y_val))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "136/135 [==============================] - 56s 410ms/step - loss: 1.1002 - accuracy: 0.7430 - val_loss: 30.7802 - val_accuracy: 0.5328\n",
            "Epoch 2/20\n",
            "136/135 [==============================] - 54s 396ms/step - loss: 0.6092 - accuracy: 0.8288 - val_loss: 21.2498 - val_accuracy: 0.6058\n",
            "Epoch 3/20\n",
            "136/135 [==============================] - 54s 397ms/step - loss: 0.4756 - accuracy: 0.8610 - val_loss: 19.5843 - val_accuracy: 0.6176\n",
            "Epoch 4/20\n",
            "136/135 [==============================] - 54s 394ms/step - loss: 0.3968 - accuracy: 0.8836 - val_loss: 12.5217 - val_accuracy: 0.6896\n",
            "Epoch 5/20\n",
            "136/135 [==============================] - 54s 394ms/step - loss: 0.3343 - accuracy: 0.9008 - val_loss: 16.6338 - val_accuracy: 0.6810\n",
            "Epoch 6/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.3140 - accuracy: 0.9050 - val_loss: 12.8128 - val_accuracy: 0.7111\n",
            "Epoch 7/20\n",
            "136/135 [==============================] - 54s 397ms/step - loss: 0.2781 - accuracy: 0.9139 - val_loss: 13.8224 - val_accuracy: 0.6799\n",
            "Epoch 8/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.2658 - accuracy: 0.9195 - val_loss: 15.2865 - val_accuracy: 0.6842\n",
            "Epoch 9/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.2661 - accuracy: 0.9199 - val_loss: 15.1083 - val_accuracy: 0.6874\n",
            "Epoch 10/20\n",
            "136/135 [==============================] - 54s 396ms/step - loss: 0.2555 - accuracy: 0.9213 - val_loss: 12.7155 - val_accuracy: 0.7465\n",
            "Epoch 11/20\n",
            "136/135 [==============================] - 54s 396ms/step - loss: 0.2459 - accuracy: 0.9234 - val_loss: 12.7438 - val_accuracy: 0.7121\n",
            "Epoch 12/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.2291 - accuracy: 0.9277 - val_loss: 11.4484 - val_accuracy: 0.7229\n",
            "Epoch 13/20\n",
            "136/135 [==============================] - 54s 400ms/step - loss: 0.2050 - accuracy: 0.9374 - val_loss: 14.9697 - val_accuracy: 0.7025\n",
            "Epoch 14/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.1811 - accuracy: 0.9420 - val_loss: 10.8762 - val_accuracy: 0.7422\n",
            "Epoch 15/20\n",
            "136/135 [==============================] - 54s 395ms/step - loss: 0.2085 - accuracy: 0.9337 - val_loss: 10.7015 - val_accuracy: 0.7540\n",
            "Epoch 16/20\n",
            "136/135 [==============================] - 53s 393ms/step - loss: 0.1854 - accuracy: 0.9441 - val_loss: 10.9377 - val_accuracy: 0.7390\n",
            "Epoch 17/20\n",
            "136/135 [==============================] - 53s 392ms/step - loss: 0.1779 - accuracy: 0.9420 - val_loss: 11.6237 - val_accuracy: 0.7401\n",
            "Epoch 18/20\n",
            "136/135 [==============================] - 53s 392ms/step - loss: 0.1622 - accuracy: 0.9512 - val_loss: 12.2476 - val_accuracy: 0.7390\n",
            "Epoch 19/20\n",
            "136/135 [==============================] - 54s 396ms/step - loss: 0.1692 - accuracy: 0.9457 - val_loss: 13.1242 - val_accuracy: 0.7207\n",
            "Epoch 20/20\n",
            "136/135 [==============================] - 53s 390ms/step - loss: 0.1806 - accuracy: 0.9439 - val_loss: 10.5546 - val_accuracy: 0.7583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nua8UWURF_8t",
        "colab_type": "text"
      },
      "source": [
        "### Validation Loss and Accuracy Plot\n",
        "* As observed in the plot the validation accuracy per epoch of the model with 2 frozen layers is lower by 10% to 15%, due to more trainable parameters in which each weights are updated per epoch\n",
        "* A huge discrepancy in validation loss plot is seen for the two models. 2 trainable layers has very high validation loss compared to 1 trainable layer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JFhEhIInJ27",
        "colab_type": "code",
        "outputId": "cadae78b-04f8-4ac1-9d92-c3e5fa829ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax_5 = fig.add_subplot(121)\n",
        "ax_5.plot(history_3.history[\"val_loss\"], label = '1 layer frozen')\n",
        "ax_5.plot(history_4.history[\"val_loss\"], label = '2 layers frozen')\n",
        "ax_5.set_title(\"validation loss\")\n",
        "ax_5.set_xlabel(\"epochs\")\n",
        "ax_5.legend()\n",
        "\n",
        "ax_6 = fig.add_subplot(122)\n",
        "ax_6.plot(history_3.history[\"val_accuracy\"], label = '1 layer frozen')\n",
        "ax_6.plot(history_4.history[\"val_accuracy\"], label = '2 layers frozen')\n",
        "ax_6.set_title(\"validation accuracy\")\n",
        "ax_6.set_xlabel(\"epochs\")\n",
        "ax_6.set_ylim(0, 1)\n",
        "ax_6.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O73Fa-MhF5_t",
        "colab_type": "text"
      },
      "source": [
        "### Test Loss and Accuracy\n",
        "#### Frozen: 1 Layer vs 2 Layers\n",
        "* The validation and test loss drastically increased with 2 trainable layers architecture\n",
        "* The validation and test accuracy decreased 10% - 15%,  with 2 trainable layers in \n",
        "\n",
        "#### Data Augmentation effects in model accuracy\n",
        "* For the 1 trainable layer model, the data augmentation affects the accuracy and loss negatively. Test Accuracy decreased and test lost increased\n",
        "* Data Augmentation affects the 2 trainable layer model positively, increased the accuracy and slightly decreased the the test loss\n",
        "\n",
        "#### Test Result Comparison\n",
        "* The data augmentation decreased the test loss in 2 trainable layers, but the loss is still high compared with the other models\n",
        "* Though the test loss of the 2 trainable layers model is high compared to the rest of the models, the accuracy is higher compared to the CNN model that was built from scratch\n",
        "* 1 trainable layer model gives the best result for both original input data and augmented data. Achieving the highest accuracy and the lowest loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebduCKiyLqO5",
        "colab_type": "code",
        "outputId": "93386224-3460-43e7-d5fb-d08c189bd992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "loss_6, accuracy_6 = model_4.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "result_list.append([\"augmented data (2 layers ResNet50)\", loss_6, accuracy_6])\n",
        "\n",
        "result_pd.loc[len(result_pd)] = result_list[1]\n",
        "result_pd"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>with Dropout</td>\n",
              "      <td>4.405936</td>\n",
              "      <td>0.386266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>without Dropout</td>\n",
              "      <td>4.074606</td>\n",
              "      <td>0.420601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1 layer frozen</td>\n",
              "      <td>0.392113</td>\n",
              "      <td>0.904506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>augmented data (1 layer ResNet50)</td>\n",
              "      <td>0.724169</td>\n",
              "      <td>0.864807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2 layers frozen</td>\n",
              "      <td>13.510264</td>\n",
              "      <td>0.715665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>augmented data (2 layers ResNet50)</td>\n",
              "      <td>9.773010</td>\n",
              "      <td>0.773605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Model       Loss  Accuracy\n",
              "0                        with Dropout   4.405936  0.386266\n",
              "1                     without Dropout   4.074606  0.420601\n",
              "2                      1 layer frozen   0.392113  0.904506\n",
              "3   augmented data (1 layer ResNet50)   0.724169  0.864807\n",
              "4                     2 layers frozen  13.510264  0.715665\n",
              "5  augmented data (2 layers ResNet50)   9.773010  0.773605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrUNSY-lkJYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}